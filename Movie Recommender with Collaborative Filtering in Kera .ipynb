{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd51aec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fiona/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d8177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "\u001b[1m978202/978202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "# Use the ratings.csv file\n",
    "movielens_data_file_url = (\n",
    "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    ")\n",
    "movielens_zipped_file = keras.utils.get_file(\n",
    "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
    ")\n",
    "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
    "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
    "\n",
    "# Only extract the data the first time the script is run.\n",
    "if not movielens_dir.exists():\n",
    "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
    "        # Extract files\n",
    "        print(\"Extracting all the files now...\")\n",
    "        zip.extractall(path=keras_datasets_path)\n",
    "        print(\"Done!\")\n",
    "\n",
    "ratings_file = movielens_dir / \"ratings.csv\"\n",
    "df = pd.read_csv(ratings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e69a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "user_ids = df[\"userId\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "movie_ids = df[\"movieId\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
    "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_encoded2movie)\n",
    "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = min(df[\"rating\"])\n",
    "max_rating = max(df[\"rating\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_movies, min_rating, max_rating\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3107943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "x = df[[\"user\", \"movie\"]].values\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "# Assuming training on 90% of the data and validating on 10%.\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b784e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = ops.tensordot(user_vector, movie_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        # The sigmoid activation forces the rating to between 0 and 1\n",
    "        return ops.nn.sigmoid(x)\n",
    "\n",
    "\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7bf628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.6556 - val_loss: 0.6209\n",
      "Epoch 2/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.6151 - val_loss: 0.6187\n",
      "Epoch 3/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.6110 - val_loss: 0.6159\n",
      "Epoch 4/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.6076 - val_loss: 0.6133\n",
      "Epoch 5/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.6081 - val_loss: 0.6145\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aadf3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step\n",
      "Showing recommendations for user: 474\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "Fugitive, The (1993) : Thriller\n",
      "Remains of the Day, The (1993) : Drama|Romance\n",
      "West Side Story (1961) : Drama|Musical|Romance\n",
      "X2: X-Men United (2003) : Action|Adventure|Sci-Fi|Thriller\n",
      "Spider-Man 2 (2004) : Action|Adventure|Sci-Fi|IMAX\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "Boondock Saints, The (2000) : Action|Crime|Drama|Thriller\n",
      "Guns of Navarone, The (1961) : Action|Adventure|Drama|War\n",
      "Snatch (2000) : Comedy|Crime|Thriller\n",
      "Gladiator (1992) : Action|Drama\n",
      "Old Boy (2003) : Mystery|Thriller\n",
      "In Bruges (2008) : Comedy|Crime|Drama|Thriller\n",
      "Dark Knight, The (2008) : Action|Crime|Drama|IMAX\n",
      "Up (2009) : Adventure|Animation|Children|Drama\n",
      "Hurt Locker, The (2008) : Action|Drama|Thriller|War\n",
      "Django Unchained (2012) : Action|Drama|Western\n"
     ]
    }
   ],
   "source": [
    "movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
    "\n",
    "# Let us get a user and see the top recommendations.\n",
    "user_id = df.userId.sample(1).iloc[0]\n",
    "\n",
    "movies_watched_by_user = df[df.userId == user_id]\n",
    "movies_not_watched = movie_df[\n",
    "    ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
    "][\"movieId\"]\n",
    "movies_not_watched = list(\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    ")\n",
    "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "user_encoder = user2user_encoded.get(user_id)\n",
    "user_movie_array = np.hstack(\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    ")\n",
    "ratings = model.predict(user_movie_array).flatten()\n",
    "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "recommended_movie_ids = [\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "]\n",
    "\n",
    "print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "print(\"====\" * 9)\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movieId.values\n",
    ")\n",
    "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.title, \":\", row.genres)\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "\n",
    "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
    "\n",
    "\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.title, \":\", row.genres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
