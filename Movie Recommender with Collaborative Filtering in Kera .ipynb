{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3fe7d58",
   "metadata": {},
   "source": [
    "## I created this toy movie recommender in kera to illustrate how to use collobrative filtering and neural networks to suggest relevant movies which fit specific users' tastes. I added detailed comments for each line of codes to assist understanding.\n",
    "\n",
    "### Author: Fiona Wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e0029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd51aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d8177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "# Use the ratings.csv file\n",
    "movielens_data_file_url = (\n",
    "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    ")\n",
    "movielens_zipped_file = keras.utils.get_file(\n",
    "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
    ")\n",
    "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
    "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
    "\n",
    "# Only extract the data the first time the script is run.\n",
    "if not movielens_dir.exists():\n",
    "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
    "        # Extract files\n",
    "        print(\"Extracting all the files now...\")\n",
    "        zip.extractall(path=keras_datasets_path)\n",
    "        print(\"Done!\")\n",
    "\n",
    "ratings_file = movielens_dir / \"ratings.csv\"\n",
    "df = pd.read_csv(ratings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de64dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Extract unique user IDs from the DataFrame and convert to a list\n",
    "user_ids = df[\"userId\"].unique().tolist()\n",
    "\n",
    "# Create a dictionary to map each user ID to a unique integer (encoding)\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "\n",
    "# Create a reverse dictionary to map the unique integer (encoding) back to the user ID\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "# Extract unique movie IDs from the DataFrame and convert to a list\n",
    "movie_ids = df[\"movieId\"].unique().tolist()\n",
    "\n",
    "# Create a dictionary to map each movie ID to a unique integer (encoding)\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "\n",
    "# Create a reverse dictionary to map the unique integer (encoding) back to the movie ID\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "\n",
    "# Add a new column 'user' to the DataFrame, mapping the original user IDs to their encoded values\n",
    "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
    "\n",
    "# Add a new column 'movie' to the DataFrame, mapping the original movie IDs to their encoded values\n",
    "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
    "\n",
    "# Calculate the number of unique users and movies\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_encoded2movie)\n",
    "\n",
    "# Ensure that the 'rating' column is of type float32\n",
    "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
    "\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = min(df[\"rating\"])\n",
    "max_rating = max(df[\"rating\"])\n",
    "\n",
    "# Print the number of users, number of movies, minimum rating, and maximum rating\n",
    "print(\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_movies, min_rating, max_rating\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5a3b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame rows and set a random seed for reproducibility\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Extract the 'user' and 'movie' columns as the input features\n",
    "x = df[[\"user\", \"movie\"]].values\n",
    "\n",
    "# Normalize the targets (ratings) between 0 and 1 for easier training\n",
    "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "\n",
    "# Assuming training on 90% of the data and validating on 10%\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],  # Features for training\n",
    "    x[train_indices:],  # Features for validation\n",
    "    y[:train_indices],  # Targets for training\n",
    "    y[train_indices:],  # Targets for validation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8cdca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the embedding vectors for users and movies\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "# Define the RecommenderNet class, a subclass of keras.Model\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # User embedding layer with regularization\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",  # He initialization for embedding weights\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),  # L2 regularization\n",
    "        )\n",
    "        # User bias embedding layer\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        \n",
    "        # Movie embedding layer with regularization\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",  # He initialization for embedding weights\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),  # L2 regularization\n",
    "        )\n",
    "        # Movie bias embedding layer\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "\n",
    "    # Define the forward pass through the network\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])  # Embedding lookup for users\n",
    "        user_bias = self.user_bias(inputs[:, 0])  # Bias lookup for users\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])  # Embedding lookup for movies\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])  # Bias lookup for movies\n",
    "        \n",
    "        # Compute dot product of user and movie embeddings\n",
    "        dot_user_movie = ops.tensordot(user_vector, movie_vector, 2)\n",
    "        \n",
    "        # Add all the components (dot product and biases)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        \n",
    "        # Apply sigmoid activation to constrain ratings between 0 and 1\n",
    "        return ops.nn.sigmoid(x)\n",
    "\n",
    "# Instantiate the RecommenderNet model with specified parameters\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "\n",
    "# Compile the model with BinaryCrossentropy loss and Adam optimizer\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),  # Binary cross-entropy loss for rating prediction\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Adam optimizer with learning rate 0.001\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c60fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.6576 - val_loss: 0.6202\n",
      "Epoch 2/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.6159 - val_loss: 0.6171\n",
      "Epoch 3/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.6086 - val_loss: 0.6135\n",
      "Epoch 4/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.6086 - val_loss: 0.6119\n",
      "Epoch 5/5\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.6083 - val_loss: 0.6114\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training data\n",
    "history = model.fit(\n",
    "    x=x_train,  # Features for training\n",
    "    y=y_train,  # Target ratings for training\n",
    "    batch_size=64,  # Number of samples per gradient update\n",
    "    epochs=5,  # Number of complete passes through the training dataset\n",
    "    verbose=1,  # Verbosity mode, 1 = progress bar\n",
    "    validation_data=(x_val, y_val),  # Data for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3725e84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m298/298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step\n",
      "Showing recommendations for user: 220\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "Apollo 13 (1995) : Adventure|Drama|IMAX\n",
      "Godfather, The (1972) : Crime|Drama\n",
      "Aliens (1986) : Action|Adventure|Horror|Sci-Fi\n",
      "Shrek (2001) : Adventure|Animation|Children|Comedy|Fantasy|Romance\n",
      "Assassination of Jesse James by the Coward Robert Ford, The (2007) : Crime|Drama|Western\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "Schindler's List (1993) : Drama|War\n",
      "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964) : Comedy|War\n",
      "Sunset Blvd. (a.k.a. Sunset Boulevard) (1950) : Drama|Film-Noir|Romance\n",
      "Streetcar Named Desire, A (1951) : Drama\n",
      "Alien (1979) : Horror|Sci-Fi\n",
      "Godfather: Part II, The (1974) : Crime|Drama\n",
      "Full Metal Jacket (1987) : Drama|War\n",
      "Amadeus (1984) : Drama\n",
      "Glory (1989) : Drama|War\n",
      "Cool Hand Luke (1967) : Drama\n"
     ]
    }
   ],
   "source": [
    "# Load the movies.csv file into a DataFrame\n",
    "movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
    "\n",
    "# Let us get a user and see the top recommendations\n",
    "user_id = df.userId.sample(1).iloc[0]  # Sample a random user ID\n",
    "\n",
    "# Get the movies watched by the sampled user\n",
    "movies_watched_by_user = df[df.userId == user_id]\n",
    "\n",
    "# Get the movie IDs that have not been watched by the user\n",
    "movies_not_watched = movie_df[\n",
    "    ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
    "][\"movieId\"]\n",
    "\n",
    "# Filter out movies that are not in the encoded movie dictionary\n",
    "movies_not_watched = list(\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    ")\n",
    "\n",
    "# Convert movie IDs to their encoded values\n",
    "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "\n",
    "# Get the encoded value for the sampled user ID\n",
    "user_encoder = user2user_encoded.get(user_id)\n",
    "\n",
    "# Create an array of the user-movie pairs for prediction\n",
    "user_movie_array = np.hstack(\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    ")\n",
    "\n",
    "# Predict ratings for the movies not watched by the user\n",
    "ratings = model.predict(user_movie_array).flatten()\n",
    "\n",
    "# Get the indices of the top 10 highest rated movies\n",
    "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the original movie IDs for the top 10 recommendations\n",
    "recommended_movie_ids = [\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "]\n",
    "\n",
    "# Print the recommendations\n",
    "print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "print(\"====\" * 9)\n",
    "\n",
    "# Print movies with high ratings from the user\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movieId.values\n",
    ")\n",
    "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.title, \":\", row.genres)\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "\n",
    "# Get and print the top 10 recommended movies\n",
    "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.title, \":\", row.genres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
